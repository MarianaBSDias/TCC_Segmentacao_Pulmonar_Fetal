<!-- antes  de enviar a vers√£o final, solicitamos que todos os coment√°rios, colocados para orienta√ß√£o ao aluno, sejam removidos do arquivo -->
# Automatiza√ß√£o de Segmenta√ß√£o Pulmonar Fetal  Atrav√©s de Modelo de Rede Neural Convolucional U-Net 3D em Imagens de Resson√¢ncia Magn√©tica

#### Aluno: [Mariana Barros dos Santos Dias](https://github.com/MarianaBSDias/)
#### Orientadora: [Manoela Kohler](https://github.com/manoelakohler).
-->

---

Trabalho apresentado ao curso [BI MASTER](https://ica.puc-rio.ai/bi-master) como pr√©-requisito para conclus√£o de curso e obten√ß√£o de cr√©dito na disciplina "Projetos de Sistemas Inteligentes de Apoio √† Decis√£o".

<!-- para os links a seguir, caso os arquivos estejam no mesmo reposit√≥rio que este README, n√£o h√° necessidade de incluir o link completo: basta incluir o nome do arquivo, com extens√£o, que o GitHub completa o link corretamente -->
- [Link para o c√≥digo](https://github.com/link_do_repositorio). <!-- caso n√£o aplic√°vel, remover esta linha -->

- [Link para a monografia](https://link_da_monografia.com). <!-- caso n√£o aplic√°vel, remover esta linha -->

- Trabalhos relacionados: <!-- caso n√£o aplic√°vel, remover estas linhas -->
    - [Nome do Trabalho 1](https://link_do_trabalho.com).
    - [Nome do Trabalho 2](https://link_do_trabalho.com).

---

### Resumo

<!-- trocar o texto abaixo pelo resumo do trabalho, em portugu√™s -->

Nos √∫ltimos anos, a an√°lise de exames de imagens tridimensionais tornou-se um componente fundamental na pr√°tica cl√≠nica e na pesquisa biom√©dica. Exames como tomografia computadorizada (TC) e resson√¢ncia magn√©tica (RM) geram volumes ricos em informa√ß√£o, que permitem avaliar √≥rg√£os, tecidos e estruturas complexas com alta precis√£o. Entretanto, a segmenta√ß√£o manual dessas imagens √© uma tarefa extremamente demorada e pode apresentar inconsist√™ncias devido √† qualidade vari√°vel das imagens. O advento das redes neurais convolucionais (CNNs) e, especificamente, da arquitetura U-Net 3D, revolucionou o campo de segmenta√ß√£o de imagens m√©dicas, permitindo a an√°lise direta em volumes completos enquanto preserva a continuidade anat√¥mica das estruturas.

Este trabalho apresenta o desenvolvimento e avalia√ß√£o de um sistema automatizado para segmenta√ß√£o pulmonar fetal em imagens de resson√¢ncia magn√©tica 3D, utilizando a arquitetura U-Net 3D implementada no framework MONAI. O pipeline abrange desde o carregamento de dados NRRD at√© a gera√ß√£o de m√°scaras segmentadas, incluindo pr√©-processamento, normaliza√ß√£o, reamostragem para voxel isotr√≥pico de 1,5 mm¬≥, redimensionamento para 128¬≥ voxels e aumento de dados.

O modelo foi treinado em GPU NVIDIA com monitoramento do coeficiente de Dice e fun√ß√£o de perda combinada (Dice + Cross Entropy), alcan√ßando 0,7608 no conjunto de teste ‚Äî resultado considerado clinicamente relevante. O uso da t√©cnica de janela deslizante (sliding window) permitiu processar volumes completos mantendo consist√™ncia espacial.

Apesar do bom desempenho, a necessidade de reduzir a resolu√ß√£o das imagens para o treinamento limitou a fidelidade das m√°scaras e causou perda de detalhes na tentativa de reescalar as m√°scaras. Mesmo assim, foi poss√≠vel obter estimativas volum√©tricas √∫teis aplicando fator de escala. Como trabalho futuro, planeja-se treinar o modelo em resolu√ß√£o original com hardware mais potente, a fim de aumentar a precis√£o, utiliza√ß√£o das m√°scaras e preservar a riqueza de detalhes para aplica√ß√µes cl√≠nicas e de pesquisa.

Palavras-chave
Segmenta√ß√£o Autom√°tica, Resson√¢ncia Magn√©tica Fetal, U-Net 3D, MONAI, Deep Learning, Processamento de Imagens M√©dicas, Pulm√£o Fetal.

### Abstract <!-- Opcional! Caso n√£o aplic√°vel, remover esta se√ß√£o -->

<!-- trocar o texto abaixo pelo resumo do trabalho, em ingl√™s -->

In recent years, the analysis of three-dimensional imaging exams has become a fundamental component in clinical practice and biomedical research. Exams such as computed tomography (CT) and magnetic resonance imaging (MRI) generate information-rich volumes that allow for the evaluation of organs, tissues, and complex structures with high precision. However, the manual segmentation of these images is an extremely time-consuming task and can present inconsistencies due to the variable quality of the images. The advent of convolutional neural networks (CNNs) and, specifically, the U-Net 3D architecture, has revolutionized the field of medical image segmentation, allowing direct analysis of entire volumes while preserving the anatomical continuity of structures.

This work presents the development and evaluation of an automated system for fetal lung segmentation in 3D magnetic resonance imaging, using the U-Net 3D architecture implemented in the MONAI framework. The pipeline covers everything from loading NRRD data to generating segmented masks, including preprocessing, normalization, resampling to 1.5 mm¬≥ isotropic voxels, resizing to 128¬≥ voxels, and data augmentation.

The model was trained on an NVIDIA GPU with monitoring of the Dice coefficient and combined loss function (Dice + Cross Entropy), achieving 0.7608 in the test set ‚Äî a result considered clinically relevant. The use of the sliding window technique allowed processing entire volumes while maintaining spatial consistency.

Despite the good performance, the need to reduce the image resolution for training limited the fidelity of the masks and caused a loss of detail when attempting to rescale them. Even so, it was possible to obtain useful volumetric estimates by applying scaling factor. As future work, it is planned to train the model at its original resolution with more powerful hardware in order to increase accuracy, mask utilization, and preserve the richness of detail for clinical and research applications.

Keywords
Automatic Segmentation, Fetal Magnetic Resonance Imaging, U-Net 3D, MONAI, Deep Learning, Medical Image Processing, Fetal Lung.


### 1. Introdu√ß√£o

Este trabalho de conclus√£o de curso (TCC) visa explorar, implementar e avaliar uma abordagem completa de segmenta√ß√£o de imagens m√©dicas 3D utilizando U-Net 3D. A pesquisa inclui todas as etapas necess√°rias: aquisi√ß√£o e pr√©-processamento de imagens, defini√ß√£o e treinamento do modelo, avalia√ß√£o quantitativa e qualitativa dos resultados e execu√ß√£o de infer√™ncia em novos volumes de teste.


1.1.
Objetivos

Os objetivos espec√≠ficos deste estudo incluem:

1.	Implementar um pipeline de pr√©-processamento adequado para imagens m√©dicas 3D, garantindo consist√™ncia espacial e intensidade padronizada.

2.	Treinar uma U-Net 3D adaptada para segmenta√ß√£o de uma estrutura espec√≠fica em volumes volum√©tricos, utilizando t√©cnicas de monitoramento de desempenho e salvamento do melhor modelo.

3.	Avaliar quantitativamente o desempenho do modelo em um conjunto de teste independente, calculando m√©tricas como Dice e desvio padr√£o.

4.	Realizar infer√™ncia em novas imagens, aplicando t√©cnicas de sliding window e p√≥s-processamento para obten√ß√£o de m√°scaras bin√°rias consistentes.

5.	Discutir os resultados, limita√ß√µes e potenciais aplica√ß√µes cl√≠nicas ou de pesquisa.


### 2. Modelagem

O sistema implementa um pipeline completo de processamento:

Aquisi√ß√£o de Resson√¢ncia Magn√©tica (RM) ‚Üí Pr√©-processamento ‚Üí Aumento de Dados ‚Üí Treinamento da U-Net 3D ‚Üí Valida√ß√£o ‚Üí Infer√™ncia


2.1.
Base de Dados

A base de dados utilizada neste estudo consiste em imagens m√©dicas volum√©tricas no formato NRRD (Nearly Raw Raster Data), um formato amplamente utilizado para armazenar dados tridimensionais de tomografia computadorizada (CT) e resson√¢ncia magn√©tica (MRI). O formato NRRD √© vantajoso para pesquisas, pois mant√©m metadados essenciais, como espa√ßamento de voxels, orienta√ß√£o e dimens√µes originais, garantindo consist√™ncia no pr√©-processamento.

Caracter√≠sticas do dataset:
‚Ä¢	Total de volumes: 342 exames.
‚Ä¢	Divis√£o:
o	Treinamento: 260 volumes (76%).
o	Valida√ß√£o: 47 volumes (14%).
o	Teste: 35 volumes (10%).
Trecho de c√≥digo com a divis√£o da base de dados:
# =============================
# SPLIT (train/val/test)
# =============================

# 10% para teste
train_val, test = train_test_split(data_dicts, test_size = 0.1, random_state = 42)

# Dos 90% restantes ‚Üí 15% para valida√ß√£o
train, val = train_test_split(train_val, test_size = 0.15, random_state = 42)

# Imprimindo os tamanhos dos conjuntos
print(f"üì¶ Train: {len(train)}  Val: {len(val)}  Test: {len(test)}")

‚Ä¢	Dimens√µes originais: entre 384 √ó 384 √ó 176 voxels, variando em profundidade (slices), altura e largura.
‚Ä¢	Modalidade: imagens em escala de cinza (single-channel), representando densidade ou intensidade do tecido.
‚Ä¢	Distribui√ß√£o aleat√≥ria: a divis√£o foi realizada garantindo representatividade para cada conjunto, evitando vieses na avalia√ß√£o do modelo.
‚Ä¢	Estrutura de diret√≥rios suportada:
Base_de_Dados/
‚îú‚îÄ‚îÄ Paciente_001/
‚îÇ   ‚îú‚îÄ‚îÄ imagem_001.nrrd            # Volume de RM original
‚îÇ   ‚îî‚îÄ‚îÄ imagem_001.seg.nrrd      # M√°scara de segmenta√ß√£o manual
‚îú‚îÄ‚îÄ Paciente_002/
‚îÇ   ‚îú‚îÄ‚îÄ imagem_002.nrrd
‚îÇ   ‚îî‚îÄ‚îÄ imagem_002.seg.nrrd
‚îî‚îÄ‚îÄ ...
A escolha desse dataset permitiu avaliar o desempenho do modelo em volumes complexos, com variabilidade anat√¥mica e de qualidade de imagem t√≠pica de exames cl√≠nicos.
Formato NRRD: Formato padr√£o para neuroimagem com suporte a metadados ricos
Metadados inclu√≠dos:
‚Ä¢	Espa√ßamento de voxel (dimens√µes f√≠sicas)
‚Ä¢	Orienta√ß√£o anat√¥mica
‚Ä¢	Tipo de dados e codifica√ß√£o

Estrutura de arquivos:
‚Ä¢	imagem_original.nrrd: Dados de intensidade da RM
‚Ä¢	imagem_original.seg.nrrd: M√°scaras de segmenta√ß√£o manual



2.2.
Hardware e Software
O treinamento e a infer√™ncia foram realizados em um ambiente de GPU CUDA, utilizando:
‚Ä¢	Python 3.10
‚Ä¢	PyTorch 2.x
‚Ä¢	MONAI 1.x (biblioteca especializada para deep learning em imagens m√©dicas)
‚Ä¢	nrrd para leitura de volumes NRRD
‚Ä¢	Matplotlib para visualiza√ß√£o de slices
A escolha do MONAI se deve √† sua integra√ß√£o nativa com PyTorch, fornecendo transforms e inferers prontos para imagens 3D.

2.3.
Pr√©-Processamento
O pr√©-processamento √© uma etapa cr√≠tica para padronizar volumes de diferentes exames, reduzir variabilidade e preparar os dados para a U-Net 3D (Kondrateva‚ÄØet‚ÄØal.,‚ÄØ2022). As etapas realizadas foram:
1.	Carregamento do volume (LoadImaged): arquivos NRRD foram convertidos em tensores PyTorch. Este passo assegura que os dados possam ser manipulados de forma eficiente em pipelines de aprendizado profundo.
Considera√ß√µes t√©cnicas:
‚Ä¢	Mant√©m dimens√µes originais do volume para evitar distor√ß√£o espacial.
‚Ä¢	Permite leitura de metadados como spacing e orienta√ß√£o.
2.	Garante o canal como primeira dimens√£o (EnsureChannelFirstd): o modelo espera entrada no formato (C, D, H, W), sendo C = 1 (volumes s√£o monocanais). Essa transforma√ß√£o evita erros de dimensionalidade e garante compatibilidade com camadas convolucionais 3D.
3.	Padroniza√ß√£o de espa√ßamento (Spacingd): todos os volumes foram reamostrados para 1,5 √ó 1,5 √ó 1,5 mm¬≥, evitando distor√ß√µes anat√¥micas, assegurando consist√™ncia volum√©trica e melhor aprendizado de padr√µes 3D pela rede.
4.	Corre√ß√£o de orienta√ß√£o (Orientationd): volumes convertidos para padr√£o RAS (Right-Anterior-Superior). Isso garante que:
‚Ä¢	O modelo aprenda localiza√ß√£o anat√¥mica relativa (direita/esquerda, superior/inferior)
‚Ä¢	Evita confus√µes em regi√µes sim√©tricas (como rins, pulm√µes, hemisf√©rios cerebrais), a corre√ß√£o garante que o modelo n√£o troque esquerda e direita. Para estruturas assim√©tricas (como f√≠gado ou ba√ßo), garante que elas estejam sempre no mesmo lado anat√¥mico, conforme a conven√ß√£o (f√≠gado √† direita, ba√ßo √† esquerda).
5.	Normaliza√ß√£o de intensidade (NormalizeIntensityd): intensidades ajustadas para m√©dia zero e desvio padr√£o unit√°rio. Isso permite que o modelo:
‚Ä¢	Seja robusto a varia√ß√µes de intensidade entre scanners
‚Ä¢	Aprenda padr√µes anat√¥micos sem vi√©s de intensidade absoluta
6.	Redimensionamento (ResizeD): volumes ajustados para 128 √ó 128 √ó 128 voxels, equilibrando detalhes anat√¥micos e limita√ß√µes de mem√≥ria GPU. Permite treinamento em GPU comum. Isso foi feito para permitir treinamento em GPU comum e reduzir o tempo computacional de infer√™ncia.
7.	Convers√£o final para tensor (EnsureTyped): compat√≠vel com MONAI para treinamento e infer√™ncia, garantindo integra√ß√£o com DataLoaders, pipelines e fun√ß√µes de loss.

Tabela 2.1: Resumo do Pr√©-Processamento
<img width="785" height="220" alt="image" src="https://github.com/user-attachments/assets/99cd69a2-2c68-4ed3-a451-640190306b6c" />

 
Ap√≥s essas transforma√ß√µes, todos os volumes apresentaram shape uniforme, pronto para entrada no modelo.


2.4.
Aumento de Dados (Data Augmentation)
Para aumentar a robustez do modelo e prevenir sobreajuste, s√£o aplicadas transforma√ß√µes geom√©tricas aleat√≥rias:
‚Ä¢	Transforma√ß√µes Espaciais:
o	Rota√ß√µes em m√∫ltiplos eixos
RandRotate90d: Rota√ß√µes de 90¬∞, 180¬∞ ou 270¬∞

o	Espelhamentos (flips) sagitais, coronais e axiais
RandFlipd: Espelhamento aleat√≥rio nos tr√™s eixos espaciais

o	Transla√ß√µes e escalas aleat√≥rias
RandCropByPosNegLabeld: Recortes aleat√≥rios balanceados (1 positivo:1 negativo)

o	Preenchimento
SpatialPadd: Preenchimento para garantir tamanho m√≠nimo para processamento, preenchimento com zeros (fundo), compat√≠vel com arquitetura da rede

‚Ä¢	Amostragem Balanceada:
o	Garante representa√ß√£o equilibrada entre tecido pulmonar e fundo
o	Previne vi√©s em dire√ß√£o √† classe majorit√°ria



2.5.
Arquitetura da U-Net 3D
O modelo U-Net 3D foi implementado por meio do m√≥dulo monai.networks.nets.UNet da biblioteca MONAI. A defini√ß√£o dos par√¢metros arquiteturais considerou a resolu√ß√£o dos volumes de entrada, a capacidade de mem√≥ria da GPU e a complexidade anat√¥mica da estrutura de interesse.
O modelo foi inicializado com pesos aleat√≥rios e treinado do zero, utilizando monitoramento cont√≠nuo da m√©trica Dice no conjunto de valida√ß√£o. O melhor modelo foi automaticamente salvo com base no maior valor de Dice alcan√ßado, garantindo que o resultado final representasse o estado de treinamento de maior desempenho.
A U-Net 3D implementada segue a estrutura cl√°ssica proposta por Ronneberger et al. (2015), com adapta√ß√µes para o processamento de imagens volum√©tricas tridimensionais. Suas principais configura√ß√µes s√£o:
‚Ä¢	Entrada: volume tridimensional (C, D, H, W), com C = 1, representando imagens em escala de cinza;
‚Ä¢	Sa√≠da: m√°scara bin√°ria tridimensional com C = 1, correspondente √† estrutura segmentada;
‚Ä¢	Filtros por n√≠vel do encoder: (8, 16, 32, 64), aumentando progressivamente conforme a profundidade da rede;
‚Ä¢	Strides (downsampling): (2, 2, 2), utilizados para redu√ß√£o sistem√°tica da dimensionalidade espacial;
‚Ä¢	Conex√µes de salto (skip connections): preservam detalhes anat√¥micos aprendidos nas camadas iniciais;
‚Ä¢	Unidades residuais: uma por n√≠vel, empregadas para evitar a degrada√ß√£o do gradiente e permitir aprendizado mais profundo;
‚Ä¢	Normaliza√ß√£o em lote (Batch Normalization) e fun√ß√£o de ativa√ß√£o ReLU aplicadas em todas as camadas, a fim de estabilizar o treinamento e acelerar a converg√™ncia.


A arquitetura compreende tr√™s componentes principais:
1.	Encoder 3D, respons√°vel por capturar padr√µes locais e globais por meio de convolu√ß√µes e opera√ß√µes de pooling;
2.	Decoder 3D, encarregado da reconstru√ß√£o da m√°scara segmentada por meio de upsampling e convolu√ß√µes sucessivas;
3.	Conex√µes de salto (skip connections), que integram informa√ß√µes de alta resolu√ß√£o do encoder com caracter√≠sticas contextuais do decoder, preservando detalhes espaciais relevantes.

A escolha da U-Net 3D fundamenta-se em tr√™s aspectos principais:
‚Ä¢	sua estrutura em formato de ‚ÄúU‚Äù, que possibilita o contexto global de cada voxel dentro do volume;
‚Ä¢	o uso de convolu√ß√µes tridimensionais (3D), que mant√™m as rela√ß√µes espaciais entre fatias e capturam a coer√™ncia anat√¥mica;
‚Ä¢	e as conex√µes de salto, essenciais para a segmenta√ß√£o precisa de √≥rg√£os pequenos ou estruturas de baixo contraste.
Essa configura√ß√£o arquitetural permite ao modelo capturar informa√ß√µes volum√©tricas detalhadas, promovendo alto desempenho e robustez em tarefas de segmenta√ß√£o m√©dica tridimensional.


2.6.
Treinamento do Modelo

O treinamento do modelo U-Net 3D foi conduzido considerando princ√≠pios voltados √† efici√™ncia do aprendizado e √† robustez na generaliza√ß√£o dos resultados. O processo contemplou 450 √©pocas de treinamento, com execu√ß√£o preferencial em GPU (CUDA), explorando a acelera√ß√£o computacional oferecida pelo processamento paralelo em unidades gr√°ficas. Quando a GPU n√£o estava dispon√≠vel, o treinamento foi automaticamente realizado em CPU, assegurando compatibilidade e portabilidade do modelo entre diferentes ambientes computacionais.

O pipeline de dados seguiu o pr√©-processamento descrito na Se√ß√£o 3.3, no qual cada volume foi padronizado para espa√ßamento isotr√≥pico, orienta√ß√£o RAS (Right‚ÄìAnterior‚ÄìSuperior) e escala de intensidade normalizada. Essa uniformiza√ß√£o foi fundamental para reduzir discrep√¢ncias entre exames provenientes de diferentes protocolos de aquisi√ß√£o, favorecendo a consist√™ncia dos dados e a efici√™ncia do aprendizado da rede.

Devido ao elevado consumo de mem√≥ria associado ao processamento de volumes tridimensionais, foi adotado batch size igual a 1, permitindo o treinamento com volumes completos sem preju√≠zo √† integridade das informa√ß√µes espaciais.

A fun√ß√£o de perda utilizada foi a Dice Loss, amplamente reconhecida como adequada para segmenta√ß√£o m√©dica bin√°ria, por penalizar de forma proporcional √† sobreposi√ß√£o entre a m√°scara predita e a m√°scara de refer√™ncia (ground truth). Essa caracter√≠stica torna a Dice Loss particularmente eficaz em cen√°rios de desbalanceamento de classes, nos quais a propor√ß√£o de voxels pertencentes √† estrutura de interesse √© significativamente menor em rela√ß√£o ao fundo.

Como otimizador, empregou-se o Adam, com taxa de aprendizado adaptativa em seus par√¢metros padr√£o, selecionado por sua estabilidade num√©rica e capacidade de converg√™ncia r√°pida em arquiteturas profundas.

Durante o treinamento, a m√©trica Dice foi monitorada a cada √©poca no conjunto de valida√ß√£o. O modelo apresentando o melhor desempenho de valida√ß√£o foi automaticamente salvo (mecanismo de checkpoint), assegurando que o modelo final correspondesse ao estado de aprendizado de maior desempenho obtido durante o processo. O mecanismo de early stopping tamb√©m foi empregado para interromper o treinamento caso n√£o houvesse melhora significativa na m√©trica de valida√ß√£o ap√≥s um n√∫mero pr√©-definido de √©pocas, prevenindo overfitting e otimizando o uso de recursos computacionais.


2.7.
Infer√™ncia

A infer√™ncia em novos volumes seguiu os mesmos passos de pr√©-processamento aplicados ao treino.
1.	Carregamento do Volume: Arquivo NRRD lido com a biblioteca nrrd e processado pelos mesmos transforms do treinamento, garantindo consist√™ncia.
2.	Adi√ß√£o de dimens√£o de batch: Tensor com shape (1, 1, D, H, W) para compatibilidade com o modelo 3D.
3.	Sliding Window Inference: Necess√°rio para processar volumes grandes que n√£o cabem na mem√≥ria GPU de uma s√≥ vez.
o	Tamanho da janela: (96, 96, 96).
o	Sobreposi√ß√£o entre janelas: 25%.
o	Batch size: 1.
4.	Aplica√ß√£o de sigmoid: Transformou logits da sa√≠da em probabilidades entre 0 e 1.
5.	Threshold de 0.5: Para binariza√ß√£o da m√°scara predita.
6.	Resultados:
‚Ä¢	Shape da m√°scara predita: (128, 128, 128).
‚Ä¢	Percentual de voxels positivos: Depende do volume, mas o pipeline permite an√°lise quantitativa do volume segmentado.
‚Ä¢	Dice Score m√©dio no conjunto de teste: 0.7608. 
‚Ä¢	Desvio padr√£o do Dice: 0.0959.




### 3. Resultados

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Proin pulvinar nisl vestibulum tortor fringilla, eget imperdiet neque condimentum. Proin vitae augue in nulla vehicula porttitor sit amet quis sapien. Nam rutrum mollis ligula, et semper justo maximus accumsan. Integer scelerisque egestas arcu, ac laoreet odio aliquet at. Sed sed bibendum dolor. Vestibulum commodo sodales erat, ut placerat nulla vulputate eu. In hac habitasse platea dictumst. Cras interdum bibendum sapien a vehicula.

Proin feugiat nulla sem. Phasellus consequat tellus a ex aliquet, quis convallis turpis blandit. Quisque auctor condimentum justo vitae pulvinar. Donec in dictum purus. Vivamus vitae aliquam ligula, at suscipit ipsum. Quisque in dolor auctor tortor facilisis maximus. Donec dapibus leo sed tincidunt aliquam.

### 4. Conclus√µes

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Proin pulvinar nisl vestibulum tortor fringilla, eget imperdiet neque condimentum. Proin vitae augue in nulla vehicula porttitor sit amet quis sapien. Nam rutrum mollis ligula, et semper justo maximus accumsan. Integer scelerisque egestas arcu, ac laoreet odio aliquet at. Sed sed bibendum dolor. Vestibulum commodo sodales erat, ut placerat nulla vulputate eu. In hac habitasse platea dictumst. Cras interdum bibendum sapien a vehicula.

Proin feugiat nulla sem. Phasellus consequat tellus a ex aliquet, quis convallis turpis blandit. Quisque auctor condimentum justo vitae pulvinar. Donec in dictum purus. Vivamus vitae aliquam ligula, at suscipit ipsum. Quisque in dolor auctor tortor facilisis maximus. Donec dapibus leo sed tincidunt aliquam.

---

Matr√≠cula: 123.456.789

Pontif√≠cia Universidade Cat√≥lica do Rio de Janeiro

Curso de P√≥s Gradua√ß√£o *Business Intelligence Master*




