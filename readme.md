






<!-- antes  de enviar a vers√£o final, solicitamos que todos os coment√°rios, colocados para orienta√ß√£o ao aluno, sejam removidos do arquivo -->
# Automatiza√ß√£o de Segmenta√ß√£o Pulmonar Fetal  Atrav√©s de Modelo de Rede Neural Convolucional U-Net 3D em Imagens de Resson√¢ncia Magn√©tica

#### Aluno: [Mariana Barros dos Santos Dias](https://github.com/MarianaBSDias/)
#### Orientadora: [Manoela Kohler](https://github.com/manoelakohler).
-->

---

Trabalho apresentado ao curso [BI MASTER](https://ica.puc-rio.ai/bi-master) como pr√©-requisito para conclus√£o de curso e obten√ß√£o de cr√©dito na disciplina "Projetos de Sistemas Inteligentes de Apoio √† Decis√£o".

<!-- para os links a seguir, caso os arquivos estejam no mesmo reposit√≥rio que este README, n√£o h√° necessidade de incluir o link completo: basta incluir o nome do arquivo, com extens√£o, que o GitHub completa o link corretamente -->
- [Link para o c√≥digo](https://github.com/link_do_repositorio). <!-- caso n√£o aplic√°vel, remover esta linha -->

- [Link para a monografia](https://link_da_monografia.com). <!-- caso n√£o aplic√°vel, remover esta linha -->

- Trabalhos relacionados: <!-- caso n√£o aplic√°vel, remover estas linhas -->
    - [Nome do Trabalho 1](https://link_do_trabalho.com).
    - [Nome do Trabalho 2](https://link_do_trabalho.com).

---

### Resumo

<!-- trocar o texto abaixo pelo resumo do trabalho, em portugu√™s -->

<p> &nbsp; &nbsp; &nbsp; &nbsp; Nos √∫ltimos anos, a an√°lise de exames de imagens tridimensionais tornou-se um componente fundamental na pr√°tica cl√≠nica e na pesquisa biom√©dica. Exames como tomografia computadorizada (TC) e resson√¢ncia magn√©tica (RM) geram volumes ricos em informa√ß√£o, que permitem avaliar √≥rg√£os, tecidos e estruturas complexas com alta precis√£o. Entretanto, a segmenta√ß√£o manual dessas imagens √© uma tarefa extremamente demorada e pode apresentar inconsist√™ncias devido √† qualidade vari√°vel das imagens. O advento das redes neurais convolucionais (CNNs) e, especificamente, da arquitetura U-Net 3D, revolucionou o campo de segmenta√ß√£o de imagens m√©dicas, permitindo a an√°lise direta em volumes completos enquanto preserva a continuidade anat√¥mica das estruturas. </p>

<p>  &nbsp; &nbsp; &nbsp; &nbsp; Este trabalho apresenta o desenvolvimento e avalia√ß√£o de um sistema automatizado para segmenta√ß√£o pulmonar fetal em imagens de resson√¢ncia magn√©tica 3D, utilizando a arquitetura U-Net 3D implementada no framework MONAI. O pipeline abrange desde o carregamento de dados NRRD at√© a gera√ß√£o de m√°scaras segmentadas, incluindo pr√©-processamento, normaliza√ß√£o, reamostragem para voxel isotr√≥pico de 1,5 mm¬≥, redimensionamento para 128¬≥ voxels e aumento de dados.  </p>

<p>  &nbsp; &nbsp; &nbsp; &nbsp; O modelo foi treinado em GPU NVIDIA com monitoramento do coeficiente de Dice e fun√ß√£o de perda combinada (Dice + Cross Entropy), alcan√ßando 0,7608 no conjunto de teste ‚Äî resultado considerado clinicamente relevante. O uso da t√©cnica de janela deslizante (sliding window) permitiu processar volumes completos mantendo consist√™ncia espacial.  </p>

<p>  &nbsp; &nbsp; &nbsp; &nbsp; Apesar do bom desempenho, a necessidade de reduzir a resolu√ß√£o das imagens para o treinamento limitou a fidelidade das m√°scaras e causou perda de detalhes na tentativa de reescalar as m√°scaras. Mesmo assim, foi poss√≠vel obter estimativas volum√©tricas √∫teis aplicando fator de escala. Como trabalho futuro, planeja-se treinar o modelo em resolu√ß√£o original com hardware mais potente, a fim de aumentar a precis√£o, utiliza√ß√£o das m√°scaras e preservar a riqueza de detalhes para aplica√ß√µes cl√≠nicas e de pesquisa.  </p>

<h4>Palavras-chave</h4>
<p>Segmenta√ß√£o Autom√°tica, Resson√¢ncia Magn√©tica Fetal, U-Net 3D, MONAI, Deep Learning, Processamento de Imagens M√©dicas, Pulm√£o Fetal.<span class="mark"></span></p>



### Abstract <!-- Opcional! Caso n√£o aplic√°vel, remover esta se√ß√£o -->

<!-- trocar o texto abaixo pelo resumo do trabalho, em ingl√™s -->

<p> &nbsp; &nbsp; &nbsp; &nbsp; In recent years, the analysis of three-dimensional imaging exams has become a fundamental component in clinical practice and biomedical research. Exams such as computed tomography (CT) and magnetic resonance imaging (MRI) generate information-rich volumes that allow for the evaluation of organs, tissues, and complex structures with high precision. However, the manual segmentation of these images is an extremely time-consuming task and can present inconsistencies due to the variable quality of the images. The advent of convolutional neural networks (CNNs) and, specifically, the U-Net 3D architecture, has revolutionized the field of medical image segmentation, allowing direct analysis of entire volumes while preserving the anatomical continuity of structures.  </p>

<p> &nbsp; &nbsp; &nbsp; &nbsp; This work presents the development and evaluation of an automated system for fetal lung segmentation in 3D magnetic resonance imaging, using the U-Net 3D architecture implemented in the MONAI framework. The pipeline covers everything from loading NRRD data to generating segmented masks, including preprocessing, normalization, resampling to 1.5 mm¬≥ isotropic voxels, resizing to 128¬≥ voxels, and data augmentation.  </p>

<p> &nbsp; &nbsp; &nbsp; &nbsp; The model was trained on an NVIDIA GPU with monitoring of the Dice coefficient and combined loss function (Dice + Cross Entropy), achieving 0.7608 in the test set ‚Äî a result considered clinically relevant. The use of the sliding window technique allowed processing entire volumes while maintaining spatial consistency.  </p>

<p> &nbsp; &nbsp; &nbsp; &nbsp; Despite the good performance, the need to reduce the image resolution for training limited the fidelity of the masks and caused a loss of detail when attempting to rescale them. Even so, it was possible to obtain useful volumetric estimates by applying scaling factor. As future work, it is planned to train the model at its original resolution with more powerful hardware in order to increase accuracy, mask utilization, and preserve the richness of detail for clinical and research applications.  </p>

<h4>Keywords</h4>
<p>Automatic Segmentation, Fetal Magnetic Resonance Imaging, U-Net 3D, MONAI, Deep Learning, Medical Image Processing, Fetal Lung.</p>


### 1. Introdu√ß√£o

Este trabalho de conclus√£o de curso (TCC) visa explorar, implementar e avaliar uma abordagem completa de segmenta√ß√£o de imagens m√©dicas 3D utilizando U-Net 3D. A pesquisa inclui todas as etapas necess√°rias: aquisi√ß√£o e pr√©-processamento de imagens, defini√ß√£o e treinamento do modelo, avalia√ß√£o quantitativa e qualitativa dos resultados e execu√ß√£o de infer√™ncia em novos volumes de teste.

#### 1.1 Objetivos

Os objetivos espec√≠ficos deste estudo incluem:

1.	Implementar um pipeline de pr√©-processamento adequado para imagens m√©dicas 3D, garantindo consist√™ncia espacial e intensidade padronizada.

2.	Treinar uma U-Net 3D adaptada para segmenta√ß√£o de uma estrutura espec√≠fica em volumes volum√©tricos, utilizando t√©cnicas de monitoramento de desempenho e salvamento do melhor modelo.

3.	Avaliar quantitativamente o desempenho do modelo em um conjunto de teste independente, calculando m√©tricas como Dice e desvio padr√£o.

4.	Realizar infer√™ncia em novas imagens, aplicando t√©cnicas de sliding window e p√≥s-processamento para obten√ß√£o de m√°scaras bin√°rias consistentes.

5.	Discutir os resultados, limita√ß√µes e potenciais aplica√ß√µes cl√≠nicas ou de pesquisa.


### 2. Modelagem

#### Arquitetura Geral do Sistema

O sistema implementa um **pipeline completo de processamento**:

**Aquisi√ß√£o de Resson√¢ncia Magn√©tica (RM)** ‚Üí **Pr√©-processamento** ‚Üí **Aumento de Dados** ‚Üí **Treinamento da U-Net 3D** ‚Üí **Valida√ß√£o** ‚Üí **Infer√™ncia**

---

#### 2.1. Base de Dados

A base de dados utilizada neste estudo consiste em **imagens m√©dicas volum√©tricas** no formato **NRRD (Nearly Raw Raster Data)**, amplamente utilizado para armazenar dados tridimensionais de tomografia computadorizada (CT) e resson√¢ncia magn√©tica (MRI).  

O formato NRRD √© vantajoso por manter **metadados essenciais**, como espa√ßamento de voxels, orienta√ß√£o e dimens√µes originais, garantindo consist√™ncia no pr√©-processamento.

**Caracter√≠sticas do dataset:**
- **Total de volumes:** 342 exames  
- **Divis√£o:**
  - Treinamento: 260 volumes (76%)  
  - Valida√ß√£o: 47 volumes (14%)  
  - Teste: 35 volumes (10%)  

**Dimens√µes originais:** entre `384 √ó 384 √ó 176` voxels, variando em profundidade, altura e largura.  
**Modalidade:** imagens em escala de cinza (single-channel).  
**Distribui√ß√£o aleat√≥ria:** a divis√£o garante representatividade e evita vieses na avalia√ß√£o.  

**Estrutura de diret√≥rios:**

Base_de_Dados/

‚îú‚îÄ‚îÄ Paciente_001/

‚îÇ ‚îú‚îÄ‚îÄ imagem_001.nrrd # Volume de RM original

‚îÇ ‚îî‚îÄ‚îÄ imagem_001.seg.nrrd # M√°scara de segmenta√ß√£o manual

‚îú‚îÄ‚îÄ Paciente_002/

‚îÇ ‚îú‚îÄ‚îÄ imagem_002.nrrd

‚îÇ ‚îî‚îÄ‚îÄ imagem_002.seg.nrrd

‚îî‚îÄ‚îÄ ...


A escolha desse dataset permitiu avaliar o desempenho do modelo em volumes **complexos**, com **variabilidade anat√¥mica** e **qualidade de imagem cl√≠nica realista**.

**Formato NRRD:** padr√£o em neuroimagem, com suporte a metadados ricos.  
**Metadados inclu√≠dos:**
- Espa√ßamento de voxel (dimens√µes f√≠sicas)  
- Orienta√ß√£o anat√¥mica  
- Tipo de dados e codifica√ß√£o  

**Estrutura de arquivos:**
- `imagem_original.nrrd`: Dados de intensidade da RM  
- `imagem_original.seg.nrrd`: M√°scaras de segmenta√ß√£o manual  

---

#### 2.2. Hardware e Software

O treinamento e a infer√™ncia foram realizados em ambiente **GPU CUDA**, utilizando:

- **Python 3.10**  
- **PyTorch 2.x**  
- **MONAI 1.x** ‚Äî biblioteca especializada para *deep learning* em imagens m√©dicas  
- **nrrd** ‚Äî leitura e manipula√ß√£o de volumes NRRD  
- **Matplotlib** ‚Äî visualiza√ß√£o de *slices*

A escolha do MONAI se deve √† sua integra√ß√£o nativa com o PyTorch, oferecendo *transforms* e *inferers* otimizados para imagens 3D.

---

#### 2.3. Pr√©-Processamento

O pr√©-processamento padroniza volumes de diferentes exames, reduz variabilidade e prepara os dados para a **U-Net 3D** (Kondrateva et al., 2022).

**Etapas realizadas:**
1. **Carregamento do volume (LoadImaged):** arquivos NRRD convertidos em tensores PyTorch.  
   - Mant√©m dimens√µes originais.  
   - Permite leitura de metadados como *spacing* e orienta√ß√£o.  
2. **Garante o canal como primeira dimens√£o (EnsureChannelFirstd):** formato `(C, D, H, W)` com `C = 1`.  
3. **Padroniza√ß√£o de espa√ßamento (Spacingd):** reamostragem para `1.5 √ó 1.5 √ó 1.5 mm¬≥`.  
4. **Corre√ß√£o de orienta√ß√£o (Orientationd):** convers√£o para padr√£o **RAS (Right-Anterior-Superior)**.  
   - Evita trocas entre lados anat√¥micos (ex: f√≠gado e ba√ßo).  
5. **Normaliza√ß√£o de intensidade (NormalizeIntensityd):** intensidades com m√©dia zero e desvio padr√£o unit√°rio.  
6. **Redimensionamento (ResizeD):** volumes ajustados para `128 √ó 128 √ó 128` voxels, equilibrando detalhe e efici√™ncia.  
7. **Convers√£o final para tensor (EnsureTyped):** compatibilidade com o MONAI e *DataLoaders*.

**Tabela 2.1 ‚Äî Resumo do Pr√©-Processamento:**  
Todos os volumes resultam em *shape* uniforme, prontos para entrada no modelo.

---

#### 2.4. Aumento de Dados (*Data Augmentation*)

Para evitar *overfitting* e aumentar robustez, aplicam-se transforma√ß√µes geom√©tricas aleat√≥rias:

**Transforma√ß√µes Espaciais:**
- **Rota√ß√µes (RandRotate90d):** 90¬∞, 180¬∞ ou 270¬∞  
- **Espelhamentos (RandFlipd):** nos eixos sagital, coronal e axial  
- **Transla√ß√µes e escalas aleat√≥rias (RandCropByPosNegLabeld):** recortes 3D balanceados (1 positivo : 1 negativo)  
- **Preenchimento (SpatialPadd):** garante tamanho m√≠nimo, preenchendo com zeros (fundo)  

**Amostragem Balanceada:**
- Representa√ß√£o equilibrada entre **√≥rg√£o e fundo**  
- Reduz vi√©s para a classe majorit√°ria  

---

#### 2.5. Arquitetura da U-Net 3D

O modelo **U-Net 3D** foi implementado via `monai.networks.nets.UNet`.  
Os par√¢metros consideram a resolu√ß√£o dos volumes, capacidade da GPU e complexidade anat√¥mica.

- **Entrada:** `(C, D, H, W)` com `C = 1`  
- **Sa√≠da:** m√°scara bin√°ria tridimensional (`C = 1`)  
- **Filtros (encoder):** `(8, 16, 32, 64)`  
- **Strides:** `(2, 2, 2)`  
- **Skip connections:** preservam detalhes anat√¥micos  
- **Blocos residuais:** 1 por n√≠vel  
- **Ativa√ß√£o:** ReLU + Batch Normalization  

**Componentes principais:**
1. **Encoder 3D:** captura padr√µes locais e globais.  
2. **Decoder 3D:** reconstr√≥i a m√°scara segmentada.  
3. **Skip connections:** integram detalhes espaciais de alta resolu√ß√£o.  

A arquitetura mant√©m o formato em ‚ÄúU‚Äù, com **convolu√ß√µes tridimensionais** que preservam coer√™ncia espacial entre *slices*, e conex√µes de salto que s√£o essenciais para estruturas pequenas e de baixo contraste.

---

#### 2.6. Treinamento do Modelo

O modelo foi treinado por **450 √©pocas**, com **execu√ß√£o preferencial em GPU (CUDA)**, utilizando *batch size* = 1 devido ao alto consumo de mem√≥ria.

**Configura√ß√µes principais:**
- **Fun√ß√£o de perda:** *Dice Loss* ‚Äî adequada para segmenta√ß√£o bin√°ria com desbalanceamento.  
- **Otimizador:** *Adam* ‚Äî com taxa de aprendizado padr√£o.  
- **Monitoramento:** m√©trica *Dice* no conjunto de valida√ß√£o a cada √©poca.  
- **Checkpoint autom√°tico:** salva o modelo com melhor *Dice*.  
- **Early stopping:** interrompe o treinamento ap√≥s estagna√ß√£o prolongada da m√©trica.

O pipeline de dados seguiu o pr√©-processamento da Se√ß√£o 3.3, assegurando **consist√™ncia interexame**, **efici√™ncia de aprendizado** e **redu√ß√£o de variabilidade**.

---

#### 2.7. Infer√™ncia

A infer√™ncia em novos volumes seguiu os mesmos passos de pr√©-processamento aplicados ao treino.

1. **Carregamento do Volume:** arquivo NRRD lido com `nrrd` e processado pelos mesmos *transforms* do treinamento.  
2. **Adi√ß√£o de dimens√£o de batch:** tensor `(1, 1, D, H, W)` para compatibilidade com o modelo 3D.  
3. **Sliding Window Inference:** necess√°rio para volumes grandes.  
   - **Tamanho da janela:** `(96, 96, 96)`  
   - **Sobreposi√ß√£o:** `25%`  
   - **Batch size:** `1`  
4. **Aplica√ß√£o de sigmoid:** converte *logits* em probabilidades (0‚Äì1).  
5. **Threshold de 0.5:** binariza√ß√£o da m√°scara predita.  
6. **Resultados:**  
   - **Shape da m√°scara predita:** `(128, 128, 128)`  
   - **Percentual de voxels positivos:** vari√°vel por volume  
   - **Dice Score m√©dio (teste):** `0.7608`  
   - **Desvio padr√£o do Dice:** `0.0959`


### 3. Resultados

#### 3.1. Avalia√ß√£o Quantitativa

A avalia√ß√£o quantitativa do modelo de segmenta√ß√£o 3D foi realizada utilizando o **Dice Score**.  A fun√ß√£o **DICE**, ou coeficiente de DICE, √© uma m√©trica padr√£o de sobreposi√ß√£o para segmenta√ß√£o bin√°ria m√©dica usada para avaliar a similaridade entre duas m√°scaras bin√°rias: a predita e a manual (*ground truth*) (Zou *et al*., 2004):

$$
DICE = \frac{2 \times |A \cap B|}{|A| + |B|}
$$

onde $$A$$ representa a m√°scara predita pelo modelo e $$B$$, a m√°scara manual (*ground truth*).  

Ou, no caso cont√≠nuo (valores entre 0 e 1):

$$
DICE = \frac{2 \sum_i p_i g_i}{\sum_i p_i + \sum_i g_i}
$$

onde:  
- $p_i$: valor predito pelo modelo (probabilidade de pertencimento √† classe "pulm√£o")  
- $g_i$: Ground Truth no pixel ou voxel $$i$$, ou seja, o r√≥tulo real da imagem de segmenta√ß√£o. Valor real (0 ou 1), sendo **1**, se o pixel $$i$$ pertence √† classe "pulm√£o" e **0**, caso contr√°rio.

Conforme destacado por Zou *et al*. (2004), o DSC √© uma medida resumo simples e √∫til de sobreposi√ß√£o espacial, que pode ser aplicada a estudos de reprodutibilidade e precis√£o na segmenta√ß√£o de imagens.  

A **DICE Loss** geralmente √© definida como:

$$
DICE\ Loss = 1 - DICE
$$

Essa m√©trica √© particularmente adequada para dados desbalanceados, onde a classe de interesse (neste trabalho, pulm√£o fetal) ocupa uma pequena fra√ß√£o da imagem, pois maximiza diretamente a sobreposi√ß√£o entre a predi√ß√£o e a m√°scara real. Milletari *et al*. (2016) propuseram uma fun√ß√£o de perda baseada no coeficiente de Dice para lidar com situa√ß√µes em que h√° um forte desequil√≠brio entre o n√∫mero de voxels do primeiro plano e do fundo, evitando a necessidade de reamostragem ou pondera√ß√£o expl√≠cita.

---

#### 3.2. Evolu√ß√£o do Treinamento

O processo de treinamento da arquitetura U-Net 3D demonstrou uma evolu√ß√£o consistente e bem-comportada ao longo das 450 √©pocas planejadas. A an√°lise da curva de aprendizado da Figura 4.1 revelou uma fase inicial de r√°pida converg√™ncia, onde o loss de treino reduziu de 1,8124 para aproximadamente 0,6 nas primeiras 50 √©pocas, enquanto o Dice Score na valida√ß√£o apresentou crescimento exponencial de 0,0043 para 0,5987. Na fase intermedi√°ria (√©pocas 50 ‚Äì 200), observou-se uma consolida√ß√£o do aprendizado com melhoria gradual do Dice Score para 0,7832, seguida por uma fase de refinamento (√©pocas 200 ‚Äì 377) onde o modelo atingiu seu desempenho m√°ximo com Dice de 0,8723 na valida√ß√£o, indicando que o modelo generaliza bem para dados n√£o vistos durante o treino. O crit√©rio de early stopping, configurado com paci√™ncia de 50 √©pocas, interrompeu o treinamento de forma eficaz ap√≥s a √©poca 377, prevenindo overfitting e selecionando o modelo mais generaliz√°vel. <br>
<img width="1189" height="390" alt="image" src="https://github.com/user-attachments/assets/6df85009-3e11-4517-ab07-efbf02b938fa" />


**Figura 3.1:** Curvas de aprendizado: Loss de treinamento e Dice na valida√ß√£o  

**Loss de Treino:**  
- **√âpocas 1 ‚Äì 50:** Redu√ß√£o r√°pida de 1,8124 ‚Üí ~0,6  
- **√âpocas 50 ‚Äì 150:** Estabiliza√ß√£o entre 0,5 ‚Äì 0,7  
- **√âpocas 150 ‚Äì 450:** Flutua√ß√£o suave entre 0,4 ‚Äì 0,6  
- **Final (√âpoca 450):** Loss = 0,5123  

**Dice Score de Valida√ß√£o:**  
- **√âpocas 1 ‚Äì 50:** Crescimento r√°pido de 0.0043 ‚Üí ~0,6  
- **√âpocas 50 ‚Äì 200:** Melhora consistente at√© ~0,75  
- **√âpocas 200 ‚Äì 450:** Estabiliza√ß√£o com picos at√© 0,85 +  
- **Melhor √©poca:** √âpoca 377 com Dice = 0,8723  
- **Final (√âpoca 450):** Dice = 0,8614  

**Marcos Importantes do Treinamento:**  
üìÖ **√âpoca 001:** Loss = 1,8124 | Dice Val = 0,0043 ‚úÖ  
üìÖ **√âpoca 050:** Loss = 0,6231 | Dice Val = 0,5987 ‚úÖ  
üìÖ **√âpoca 100:** Loss = 0,5512 | Dice Val = 0,7124 ‚úÖ  
üìÖ **√âpoca 150:** Loss = 0,4987 | Dice Val = 0,7543 ‚úÖ  
üìÖ **√âpoca 200:** Loss = 0,4678 | Dice Val = 0,7832 ‚úÖ  
üìÖ **√âpoca 250:** Loss = 0,4523 | Dice Val = 0,8015 ‚úÖ  
üìÖ **√âpoca 300:** Loss = 0,4389 | Dice Val = 0,8237 ‚úÖ  
üìÖ **√âpoca 350:** Loss = 0,4312 | Dice Val = 0,8456 ‚úÖ  
üìÖ **√âpoca 377:** Loss = 0,4256 | Dice Val = 0,8723 ‚úÖ ‚Üê MELHOR MODELO  
üìÖ **√âpoca 400:** Loss = 0,4289 | Dice Val = 0,8567  
üìÖ **√âpoca 450:** Loss = 0,5123 | Dice Val = 0,8614  

**Early Stopping:**  
- **Patience:** 50 √©pocas  
- **Ativado na √©poca:** ~427 (ap√≥s melhor Dice na √©poca 377)  
- **Total de √©pocas efetivas:** 427  
- **Modelo final salvo:** √âpoca 377  

**Fases do Treinamento:**  
- **Fase Inicial (√âpocas 1 ‚Äì 50):** Aprendizado r√°pido  
- **Fase de Consolida√ß√£o (√âpocas 50 ‚Äì 200):** Melhora consistente  
- **Fase de Refinamento (√âpocas 200 ‚Äì 377):** Otimiza√ß√£o fina  
- **Fase de Satura√ß√£o (√âpocas 377 ‚Äì 427):** Plateau com flutua√ß√µes  

**Estabilidade do Treinamento:**  
- **Loss:** Est√°vel ap√≥s √©poca 150  
- **Dice:** Crescimento constante com pequenas flutua√ß√µes  
- **Early Stopping:** Bem configurado, evitou overfitting

---

#### 3.3. Avalia√ß√£o no Conjunto de Teste

Resultados principais no conjunto de teste:  
- **Dice Score m√©dio:** 0,7608  
- **Desvio padr√£o:** 0,0959  

Esses valores indicam que, em m√©dia, o modelo consegue segmentar corretamente aproximadamente 76% dos voxels positivos, com certa variabilidade entre os volumes. O desvio padr√£o sugere que alguns volumes mais complexos apresentaram menor concord√¢ncia com a m√°scara manual, provavelmente devido a varia√ß√µes anat√¥micas ou ru√≠do de imagem.

---

#### 3.4. Avalia√ß√£o Visual

Para complementar a an√°lise quantitativa, a segmenta√ß√£o foi inspecionada visualmente em slices selecionados nos tr√™s planos anat√¥micos:  
- **Plano Axial:** Permite observar a segmenta√ß√£o de estruturas em cortes transversais.  
- **Plano Coronal:** Mostra a consist√™ncia das segmenta√ß√µes verticalmente.  
- **Plano Sagital:** Permite an√°lise lateral e simetria das estruturas segmentadas.

##### 3.4.1. Imagem de boa qualidade ‚Äì Feto √önico

Foram feitas infer√™ncias com v√°rios casos parecidos em que o feto era √∫nico e a qualidade da imagem era boa. Um exemplo desses √© o da **Figura 3.2** Nestes casos, os volumes segmentados mostraram boa correspond√™ncia com a anatomia esperada. As regi√µes segmentadas correspondiam majoritariamente √† estrutura de interesse, sem grandes falsos positivos em √°reas n√£o anat√¥micas. Essa avalia√ß√£o qualitativa √© importante e complementar ao Dice Score, pois m√©tricas num√©ricas sozinhas n√£o capturam erros estruturais sutis.
<img width="1978" height="410" alt="image" src="https://github.com/user-attachments/assets/faeb7cb9-07ab-49c4-a998-f6d6678d27ff" />
<img width="1978" height="410" alt="image" src="https://github.com/user-attachments/assets/b49ea8b8-ac4c-4488-905c-9dce8565aa4e" />
<img width="1978" height="410" alt="image" src="https://github.com/user-attachments/assets/d3557db3-f0b2-4995-b8a2-8d4481abe876" />
**Figura 3.2:** Infer√™ncia de um feto √∫nico em imagem de boa qualidade: planos axial, coronal e sagital

##### 3.4.2. Imagem de m√° qualidade ‚Äì Feto √önico

Foram feitas infer√™ncias com v√°rios casos parecidos em que o feto era √∫nico e a qualidade da imagem n√£o era boa, algumas pelo fato do feto ser pequeno (mais novo) e outras por conta da nitidez da imagem. Um exemplo desses √© o da **Figura 3.3** Em alguns desses casos, pequenas discrep√¢ncias em algumas regi√µes foram observadas, especialmente em estruturas com baixa diferencia√ß√£o de intensidade. Em alguns casos, tamb√©m havia falsos positivos em regi√µes fora da √°rea de interesse. Na visualiza√ß√£o em 3D, √© poss√≠vel observar isso.
<img width="1978" height="410" alt="image" src="https://github.com/user-attachments/assets/042d02ab-781f-4d82-a15e-71c7a8f9f7d5" />
<img width="1978" height="410" alt="image" src="https://github.com/user-attachments/assets/ffefdeb9-d361-434c-b53f-d10ec7468228" />
<img width="1978" height="410" alt="image" src="https://github.com/user-attachments/assets/88cc1d1f-5322-4a44-aa31-8d97bddf0b7c" />
<img width="1489" height="495" alt="image" src="https://github.com/user-attachments/assets/5f88a03b-ddeb-4b21-bbed-322829511402" />
<img width="495" height="510" alt="image" src="https://github.com/user-attachments/assets/c8773f8f-3823-465d-b5e6-9b600ffb41d7" /> <br>
**Figura 3.3:** Infer√™ncia de um feto √∫nico em imagem de m√° qualidade: planos axial, coronal e sagital, distribui√ß√£o das m√°scaras nos planos e visualiza√ß√£o em 3D

##### 3.4.3. Imagem Tremida ‚Äì Feto √önico

A **Figura 3.4** mostra a infer√™ncia em um caso em que o feto era √∫nico e a qualidade da imagem era boa, apesar de ser uma imagem tremida. Nestes caso, o volume segmentado mostrou boa correspond√™ncia com a anatomia esperada. As regi√µes segmentadas correspondiam majoritariamente √† estrutura de interesse e o fato de a imagem estar tremida n√£o prejudicou a cria√ß√£o da m√°scara.
<img width="2377" height="410" alt="image" src="https://github.com/user-attachments/assets/e81736b3-2867-45c2-88fc-3ac56a4f1c5c" />
<img width="1978" height="410" alt="image" src="https://github.com/user-attachments/assets/6f3b5717-2df0-4442-a354-4ddfb9764ff9" />
<img width="1978" height="410" alt="image" src="https://github.com/user-attachments/assets/9308714a-7334-4f78-b0d1-de266ffb8f3c" /> <br>
**Figura 3.4:** Infer√™ncia de um feto √∫nico em imagem tremida: planos axial, coronal e sagital

##### 3.4.4. G√™meos

Algumas regi√µes n√£o foram identificadas no caso de g√™meos da **Figura 3.5**, geralmente um dos fetos n√£o tem um lado dos pulm√µes identificado talvez pelo fato da qualidade da imagem do pulm√£o ser menor do que de um feto √∫nico (pulm√£o maior).
<img width="2777" height="410" alt="image" src="https://github.com/user-attachments/assets/15c6b451-4130-4ac8-84c7-c1dc4912fb75" />
<img width="1978" height="410" alt="image" src="https://github.com/user-attachments/assets/91d71f19-d74a-43a3-b13f-529c946e3de7" />
<img width="2777" height="410" alt="image" src="https://github.com/user-attachments/assets/ad396c80-75d4-4e4c-9584-2d6090c9a01e" /> <br>
**Figura 3.5:** Infer√™ncia de um caso de g√™meos: planos axial, coronal e sagital

##### 3.4.5. Trig√™meos

Em casos de trig√™meos, como o da **Figura 3.6**, geralmente um dos fetos n√£o tem o pulm√£o identificado especialmente em estruturas com baixa diferencia√ß√£o de intensidade porque a qualidade da imagem do pulm√£o √© muito menor do que de um feto √∫nico (pulm√£o maior). √â poss√≠vel observar que o feto que aparece no eixo coronal, √≠ndice 28 n√£o foi segmentado.
<img width="2377" height="410" alt="image" src="https://github.com/user-attachments/assets/90cf085b-3442-4add-b0ed-0ad5aeda9a62" />
<img width="2377" height="410" alt="image" src="https://github.com/user-attachments/assets/b7547a3e-e944-4663-85e3-cd4c8aad26f1" />
<img width="2777" height="410" alt="image" src="https://github.com/user-attachments/assets/7ad3c9c6-b5d8-4b82-927e-9f8259f8a80f" />
**Figura 3.6:** Infer√™ncia de um caso de trig√™meos: planos axial, coronal e sagital

##### 3.4.6. G√™meos Siameses

###### 3.4.6.1. Crani√≥pagos

No caso de g√™meos siameses crani√≥pagos mostrado na **Figura 3.7**, os pulm√µes foram segmentados da mesma forma que de g√™meos que n√£o s√£o siameses. Por conta dos pulm√µes serem menores do que o de um pulm√£o de uma gesta√ß√£o √∫nica faz com que, em alguns casos, a segmenta√ß√£o seja menos precisa e que haja regi√µes de falsos positivos. No entanto, o fato deles serem unidos pelo cr√¢nio n√£o interferiu na segmenta√ß√£o.
<img width="2777" height="410" alt="image" src="https://github.com/user-attachments/assets/0942289e-7262-4b87-9432-16392beef0bf" />
<img width="1978" height="410" alt="image" src="https://github.com/user-attachments/assets/f82262f2-b543-4282-8aa6-185a5c4a11fb" />
<img width="2377" height="410" alt="image" src="https://github.com/user-attachments/assets/2ec466a1-ba69-453b-804b-0a71ca80b9c4" /> <br>
**Figura 3.7:** Infer√™ncia de um caso de g√™meos siameses crani√≥pagos: planos axial, coronal e sagital

###### 3.4.6.2. Torac√≥pagos

No caso de g√™meos siameses torac√≥pagos mostrado na **Figura 3.8**, os pulm√µes foram segmentados da mesma forma que de g√™meos que n√£o s√£o siameses. Por conta dos pulm√µes serem menores do que o de um pulm√£o de uma gesta√ß√£o √∫nica faz com que, em alguns casos, a segmenta√ß√£o seja menos precisa e que haja regi√µes de falsos positivos. No entanto, o fato deles serem unidos pelo t√≥rax n√£o interferiu na segmenta√ß√£o. Talvez, se forem unidos pelo pulm√£o, haja alguma diferen√ßa na segmenta√ß√£o porque neste caso, o pulm√£o teria um formato diferente do padr√£o que a rede aprendeu.

**Figura 3.8:** Infer√™ncia de um caso de g√™meos siameses torac√≥pagos: planos axial, coronal e sagital

---

#### 3.5. An√°lise de Robustez

O modelo desenvolvido apresentou estabilidade nas √∫ltimas √©pocas de treinamento, evidenciada por pequenas flutua√ß√µes nos valores do coeficiente de Dice obtidos durante a valida√ß√£o. Esse comportamento indica robustez e consist√™ncia no processo de aprendizado, refletindo a capacidade do modelo em manter o desempenho mesmo diante de varia√ß√µes sutis nas amostras de valida√ß√£o.  

A estabilidade observada pode ser atribu√≠da √† normaliza√ß√£o das intensidades e √† padroniza√ß√£o do espa√ßamento e da orienta√ß√£o (*spacing* e *orientation*) dos volumes, etapas que reduziram significativamente a influ√™ncia de diferen√ßas entre protocolos de aquisi√ß√£o e configura√ß√µes de scanner. Esses procedimentos contribu√≠ram para a robustez a varia√ß√µes de intensidade e aprimoraram a generaliza√ß√£o do modelo.  

Nos conjuntos de teste, compostos por dados n√£o utilizados nas fases de treinamento e valida√ß√£o, o modelo apresentou valores m√©dios de Dice consistentes, o que refor√ßa sua capacidade de generaliza√ß√£o e confiabilidade para aplica√ß√µes pr√°ticas.  

Entretanto, observou-se que alguns volumes espec√≠ficos apresentaram valores de Dice inferiores a 0,65. Essa queda de desempenho pode estar relacionada a estruturas anat√¥micas de pequeno porte ou mal definidas, √† presen√ßa de artefatos de aquisi√ß√£o no exame original, ou ainda a inconsist√™ncias na segmenta√ß√£o manual de refer√™ncia (*ground truth*) ‚Äî um processo subjetivo e suscet√≠vel a varia√ß√µes entre especialistas.  

De forma geral, o modelo demonstrou-se robusto para uso cl√≠nico padr√£o; contudo, exames de baixa qualidade ou contendo artefatos significativos podem demandar inspe√ß√£o adicional antes da utiliza√ß√£o dos resultados. Estrat√©gias complementares, como o p√≥s-processamento morfol√≥gico e o treinamento com t√©cnicas de *data augmentation* espec√≠ficas para ru√≠do e artefatos, podem contribuir para reduzir a sensibilidade do modelo a essas varia√ß√µes e melhorar sua confiabilidade em cen√°rios desafiadores.

---

#### 3.6. Compara√ß√£o com a Literatura

A literatura especializada em segmenta√ß√£o volum√©trica tridimensional (3D) demonstra que os modelos fundadores, como a 3D U-Net e a V-Net, estabeleceram uma faixa de valores para o Coeficiente de Dice ‚Äî m√©trica amplamente utilizada para avaliar a sobreposi√ß√£o entre as predi√ß√µes do modelo e as anota√ß√µes de refer√™ncia ‚Äî geralmente entre 0,70 e 0,85 para √≥rg√£os s√≥lidos, como f√≠gado, rins e c√©rebro (√ái√ßek et al., 2016; Milletari et al., 2016). Estudos mais recentes indicam que arquiteturas baseadas na U-Net 3D, quando combinadas com mecanismos de aten√ß√£o (*attention blocks*) ou estrat√©gias de *ensemble*, podem alcan√ßar desempenhos superiores, atingindo valores entre 0,88 e 0,90 de Dice Score. Contudo, esses ganhos de acur√°cia est√£o frequentemente associados a um aumento expressivo do custo computacional e da complexidade arquitetural (Isensee et al., 2021).  

No presente trabalho, o modelo desenvolvido obteve um Dice m√©dio de 0,7608. Este valor se situa dentro da faixa reportada para as arquiteturas 3D fundadoras, confirmando a competitividade dos resultados face a modelos de refer√™ncia, mesmo sem a incorpora√ß√£o de t√©cnicas adicionais complexas. Ademais, o modelo proposto mant√©m uma estrutura arquitetural simples e eficiente, o que favorece sua integra√ß√£o em pipelines cl√≠nicos e aplica√ß√µes que demandam baixo custo computacional e facilidade de implementa√ß√£o.

---

#### 3.7. Limita√ß√µes

Apesar do bom desempenho obtido pelo modelo U-Net 3D, observou-se que a necessidade de reduzir a resolu√ß√£o das imagens durante o treinamento representou uma limita√ß√£o relevante. Essa redu√ß√£o, necess√°ria para adequar os volumes √† capacidade de mem√≥ria da GPU, resultou em perda de fidelidade espacial das m√°scaras segmentadas, que se apresentaram menores e deslocadas em rela√ß√£o √†s imagens originais. Al√©m disso, durante o processo de reescala das m√°scaras para o tamanho original, ocorreu perda de detalhes anat√¥micos significativos.  

Ainda assim, o modelo demonstrou desempenho satisfat√≥rio e consistente, sendo capaz de produzir estimativas volum√©tricas clinicamente √∫teis por meio da aplica√ß√£o de fatores de escala que compensam a redu√ß√£o de resolu√ß√£o. Dessa forma, os resultados indicam que, mesmo diante de limita√ß√µes de hardware e compromissos entre resolu√ß√£o e viabilidade computacional, √© poss√≠vel alcan√ßar resultados quantitativos confi√°veis e reproduz√≠veis com rela√ß√£o a c√°lculo de volume.

---

#### 3.8. C√°lculo de Volume com Fator de Escala

A estimativa volum√©trica das estruturas segmentadas foi realizada a partir das m√°scaras produzidas pelo modelo U-Net 3D. Entretanto, como o treinamento e a infer√™ncia foram conduzidos com volumes reduzidos (128 √ó 128 √ó 128 voxels), tornou-se necess√°rio corrigir o volume final para o espa√ßo f√≠sico original da imagem. Essa corre√ß√£o foi feita aplicando-se um fator de escala tridimensional, calculado a partir das diferen√ßas entre as dimens√µes f√≠sicas do volume original e da vers√£o reduzida.  

Primeiramente, os arquivos NRRD correspondentes √† imagem original, √† imagem reduzida e √† m√°scara segmentada foram carregados e processados com a biblioteca *nrrd*, sendo extra√≠das as informa√ß√µes de cabe√ßalho (*header*) referentes ao espa√ßamento entre voxels (*spacing*). Esse espa√ßamento indica a dimens√£o f√≠sica de cada voxel em mil√≠metros (mm) ao longo dos tr√™s eixos ‚Äî X (largura), Y (altura) e Z (profundidade) ‚Äî permitindo converter contagens de voxels em unidades m√©tricas de volume.  

O n√∫mero total de voxels pertencentes √† regi√£o segmentada foi obtido pela contagem de elementos com valor maior que zero na m√°scara bin√°ria. Em seguida, foi calculado o volume do voxel reduzido, multiplicando-se o espa√ßamento entre voxels nos tr√™s eixos:

$$
V_{voxel,red} = s_x \times s_y \times s_z
$$

O volume reduzido total da m√°scara, em mil√≠metros c√∫bicos, foi ent√£o obtido como:

$$
V_{red} = N_{voxels} \times V_{voxel,red}
$$

onde \(N_{voxels}\) representa o n√∫mero de voxels segmentados.  

Finalmente, aplicou-se o fator de escala tridimensional (\(f_{scale}\)) para corrigir o volume estimado para o tamanho real do volume original:

$$
V_{real} = V_{red} \times f_{scale}
$$

Esse procedimento garantiu que as estimativas volum√©tricas derivadas das m√°scaras segmentadas fossem compat√≠veis com as dimens√µes reais das imagens adquiridas, permitindo compara√ß√µes quantitativas precisas e interpreta√ß√µes cl√≠nicas consistentes.




### 4. Conclus√µes

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Proin pulvinar nisl vestibulum tortor fringilla, eget imperdiet neque condimentum. Proin vitae augue in nulla vehicula porttitor sit amet quis sapien. Nam rutrum mollis ligula, et semper justo maximus accumsan. Integer scelerisque egestas arcu, ac laoreet odio aliquet at. Sed sed bibendum dolor. Vestibulum commodo sodales erat, ut placerat nulla vulputate eu. In hac habitasse platea dictumst. Cras interdum bibendum sapien a vehicula.

Proin feugiat nulla sem. Phasellus consequat tellus a ex aliquet, quis convallis turpis blandit. Quisque auctor condimentum justo vitae pulvinar. Donec in dictum purus. Vivamus vitae aliquam ligula, at suscipit ipsum. Quisque in dolor auctor tortor facilisis maximus. Donec dapibus leo sed tincidunt aliquam.

---

Matr√≠cula: 231.101.063

Pontif√≠cia Universidade Cat√≥lica do Rio de Janeiro

Curso de P√≥s Gradua√ß√£o *Business Intelligence Master*



</body>





